{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importDataFromMatFiles(rootDir):\n",
    "    \"\"\"\n",
    "    Param: rootDir: The parent directory to the directories that start with Copy ....\n",
    "                    For example, in this case, rootDir = \"/Users/jameshe/Documents/radar_ura/FirstBatch\"\n",
    "    \"\"\"\n",
    "    xList = list()\n",
    "    yList = list()\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    for f in os.scandir(rootDir):\n",
    "        if f.is_dir():\n",
    "            with open(os.path.join(f.path, \"test_data.json\")) as labelFile:\n",
    "                labels = json.load(labelFile)\n",
    "                occupancyLabel = labels[\"Occupied_Seats\"]\n",
    "            for file in os.scandir(os.path.join(f.path, \"SavedVars_RF_Data\")):\n",
    "                frame = sio.loadmat(file)\n",
    "                image = frame[\"Image\"]\n",
    "                mask = frame[\"Mask\"]\n",
    "                image[mask == False] = 0\n",
    "                xList.append(image)\n",
    "                yList.append(occupancyLabel)\n",
    "    yList = mlb.fit_transform(yList)\n",
    "    xList = np.array(xList)\n",
    "    xList = np.absolute(xList)\n",
    "    return (xList, yList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveData(data, path, fileName):\n",
    "    \"\"\"\n",
    "    open file mode w: write, if the file exist, erase it\n",
    "    open file mode b: open the file as a binary file\n",
    "    \"\"\"\n",
    "    filePath = os.path.join(path, fileName)\n",
    "    with open(filePath,'wb') as pickleFileHandle:\n",
    "        pickle.dump(data, pickleFileHandle)\n",
    "        pickleFileHandle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(path, fileName):\n",
    "    \"\"\"\n",
    "    open file mode b: open the file as a binary file\n",
    "    open file mode r: read file\n",
    "    \"\"\"\n",
    "    filePath = os.path.join(path, fileName)\n",
    "    with open(filePath, 'rb') as pickleFileHandle:\n",
    "        data = pickle.load(pickleFileHandle)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = importDataFromMatFiles(\"/Users/jameshe/Documents/radar_ura/FirstBatch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/pytorch-step-by-step-implementation-3d-convolution-neural-network-8bf38c70e8b3\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "\n",
    "batch_size = 100 #We pick beforehand a batch_size that we will use for the training\n",
    "\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(x_train,y_train)\n",
    "test = torch.utils.data.TensorDataset(x_test,y_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "# Create CNN Model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        self.conv_layer1 = self._conv_layer_set(3, 32)\n",
    "        self.conv_layer2 = self._conv_layer_set(32, 64)\n",
    "        self.fc1 = nn.Linear(2**3*64, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.batch=nn.BatchNorm1d(128)\n",
    "        self.drop=nn.Dropout(p=0.15)        \n",
    "        \n",
    "    def _conv_layer_set(self, in_c, out_c):\n",
    "        conv_layer = nn.Sequential(\n",
    "        nn.Conv3d(in_c, out_c, kernel_size=(3, 3, 3), padding=0),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.MaxPool3d((2, 2, 2)),\n",
    "        )\n",
    "        return conv_layer\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set 1\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.batch(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "#Definition of hyperparameters\n",
    "n_iters = 4500\n",
    "num_epochs = n_iters / (len(train_x) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "# Create CNN\n",
    "model = CNNModel()\n",
    "#model.cuda()\n",
    "print(model)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model training\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        train = Variable(images.view(100,3,16,16,16))\n",
    "        labels = Variable(labels)\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        # Calculate softmax and ross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        if count % 50 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                \n",
    "                test = Variable(images.view(100,3,16,16,16))\n",
    "                # Forward propagation\n",
    "                outputs = model(test)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "        if count % 500 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data, accuracy))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitvayyarradarconda6b1643d409fe49e8800faf9b4958cadf",
   "display_name": "Python 3.8.3 64-bit ('vayyar_radar': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}